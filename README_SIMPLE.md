# METABOLIC_BACKEND - Simplified Structure

A clean, health news API backend with automated scraping and URL validation.

## ğŸ“ Simple File Structure

```
METABOLIC_BACKEND/
â”œâ”€â”€ app/                           # Main application
â”‚   â”œâ”€â”€ main.py                   # FastAPI application
â”‚   â”œâ”€â”€ utils.py                  # Database & utility functions
â”‚   â”œâ”€â”€ url_validator.py          # URL validation
â”‚   â”œâ”€â”€ health_categories.yml     # Content categories
â”‚   â”œâ”€â”€ scraper_config.py         # Scraper configuration
â”‚   â””â”€â”€ scrapers/                 # News scrapers
â”‚       â”œâ”€â”€ master_health_scraper.py
â”‚       â”œâ”€â”€ smart_news_aggregator.py
â”‚       â””â”€â”€ social_media_scraper.py
â”œâ”€â”€ data/                         # Database storage
â”‚   â””â”€â”€ articles.db              # SQLite database
â”œâ”€â”€ scripts/                     # Utility scripts
â”‚   â”œâ”€â”€ cleanup_urls.py         # Clean problematic URLs
â”‚   â”œâ”€â”€ check_urls.py           # Check URL status
â”‚   â”œâ”€â”€ check_specific_urls.py  # Detailed URL checker
â”‚   â””â”€â”€ test_url_validation.py  # Test URL validation
â”œâ”€â”€ deploy/                      # Deployment files
â”‚   â”œâ”€â”€ docker-compose.yml      # Docker setup
â”‚   â”œâ”€â”€ Dockerfile              # Container config
â”‚   â”œâ”€â”€ nginx.conf              # Web server config
â”‚   â”œâ”€â”€ render.yaml             # Render deployment
â”‚   â””â”€â”€ env.production          # Production environment
â”œâ”€â”€ run.py                       # Simple command runner
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README_SIMPLE.md            # This file
```

## ğŸš€ Quick Start

### Run the API Server
```bash
python run.py api
```

### Run News Scraper
```bash
python run.py scraper
```

### Clean Database
```bash
python run.py clean
```

### Check URLs
```bash
python run.py check
```

## ğŸ“Š API Endpoints

- **Search**: `/api/v1/search?q=diabetes`
- **Categories**: `/api/v1/category/diseases`
- **Tags**: `/api/v1/tag/nutrition`
- **Health Check**: `/api/v1/health`
- **Stats**: `/api/v1/stats`

## ğŸ”§ Configuration

All configuration is now centralized in the `app/` directory:
- `health_categories.yml` - Content categories
- `scraper_config.py` - Scraper settings
- `main.py` - API configuration

## ğŸ› ï¸ Development

1. **Install dependencies**: `pip install -r requirements.txt`
2. **Run API**: `python run.py api`
3. **Access docs**: http://localhost:8000/docs

## ğŸš¢ Deployment

All deployment files are in the `deploy/` directory:
- Docker: `docker-compose -f deploy/docker-compose.yml up`
- Render: Uses `deploy/render.yaml`

## ğŸ§¹ Maintenance

- **Clean URLs**: `python run.py clean`
- **Check Status**: `python run.py check` 
- **Test Validation**: `python scripts/test_url_validation.py`

## âœ¨ Features

- âœ… Clean, validated URLs (no more example.com!)
- âœ… Real-time health news scraping
- âœ… Comprehensive search & filtering
- âœ… Automated content categorization
- âœ… Production-ready deployment

---

**Simple. Clean. Reliable.** ğŸ¥
